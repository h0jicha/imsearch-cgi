{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f77236-827d-432a-be58-7a34603a00c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "feature_names = [\"bgr_1x1\", \"bgr_2x2\", \"bgr_3x3\",\n",
    "                 \"hsv_1x1\", \"hsv_2x2\", \"hsv_3x3\",\n",
    "                 \"luv_1x1\", \"luv_2x2\", \"luv_3x3\",\n",
    "                 \"gabor\", \"dnn\"]\n",
    "\n",
    "def extract_color_histogram(image, color_space, grid=(1, 1)):\n",
    "    histograms = []\n",
    "\n",
    "    h_step, w_step = image.shape[0] // grid[0], image.shape[1] // grid[1]\n",
    "\n",
    "    for y in range(grid[0]):\n",
    "        for x in range(grid[1]):\n",
    "            cell = image[y * h_step:(y + 1) * h_step, x * w_step:(x + 1) * w_step]\n",
    "\n",
    "            if color_space == \"hsv\":\n",
    "                img = cv2.cvtColor(cell, cv2.COLOR_BGR2HSV)\n",
    "            elif color_space == \"luv\":\n",
    "                img = cv2.cvtColor(cell, cv2.COLOR_BGR2Luv)\n",
    "            else:\n",
    "                img = cell\n",
    "\n",
    "            hist = cv2.calcHist([img], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "            histograms.append(cv2.normalize(hist, hist).flatten())\n",
    "\n",
    "    return np.concatenate(histograms)\n",
    "\n",
    "def extract_gabor_features(image, ksize=31, sigma=1.0, theta=np.pi/4, lambd=15.0, gamma=0.02, psi=0):\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gabor_kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, ktype=cv2.CV_32F)\n",
    "    filtered_image = cv2.filter2D(image_gray, cv2.CV_8UC3, gabor_kernel)\n",
    "    return filtered_image.flatten()\n",
    "\n",
    "def extract_dnn_features(image, model):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    input_tensor = transform(pil_image).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = model(input_tensor)\n",
    "\n",
    "    return features.squeeze().numpy()\n",
    "\n",
    "def main():\n",
    "    prefix = '/export/space0/tanabe-h/data/kadai3a/'\n",
    "    img_directory = prefix + \"img\"\n",
    "    features_directory = prefix + \"features\"\n",
    "\n",
    "    if not os.path.exists(features_directory):\n",
    "        os.makedirs(features_directory)\n",
    "\n",
    "    img_files = [f for f in os.listdir(img_directory) if f.endswith(\".jpg\")]\n",
    "    \n",
    "    model = models.vgg16(pretrained=True)\n",
    "    model = model.eval()\n",
    "    model.classifier = model.classifier[:-1]\n",
    "\n",
    "    for idx, feature_name in enumerate(feature_names):\n",
    "        feature_data = {}\n",
    "\n",
    "        for img_file in img_files:\n",
    "            file_path = os.path.join(img_directory, img_file)\n",
    "            image = cv2.imread(file_path)\n",
    "            file_index = img_file[:-4]\n",
    "\n",
    "            if feature_name.startswith(\"bgr\") or feature_name.startswith(\"hsv\") or feature_name.startswith(\"luv\"):\n",
    "                color_space, grid = feature_name.split(\"_\")\n",
    "                grid = int(grid[0]), int(grid[0])\n",
    "                feature_data[file_index] = extract_color_histogram(image, color_space, grid=grid)\n",
    "            elif feature_name == \"gabor\":\n",
    "                feature_data[file_index] = extract_gabor_features(image)\n",
    "            elif feature_name == \"dnn\":\n",
    "                feature_data[file_index] = extract_dnn_features(image, model)\n",
    "\n",
    "        np.savez(os.path.join(features_directory, f\"{feature_name}_features.npz\"), **feature_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f95c24-2fbc-4092-a07a-0b5ca378d148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_DIR = '/export/space0/tanabe-h/data/kadai3a/features/'\n",
    "def load_features(feature_name):\n",
    "    features_path = os.path.join(FEATURES_DIR, f\"{feature_name}_features.npz\")\n",
    "    npz_data = np.load(features_path)\n",
    "    return {key: npz_data[key] for key in npz_data.keys()}\n",
    "\n",
    "# load_features('bgr_1x1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
